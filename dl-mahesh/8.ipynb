{
 "cells": [
  {
   "cell_type": "raw",
   "id": "6ecace31-91d8-4185-aa84-141a1181db63",
   "metadata": {},
   "source": [
    "Implement the Continuous Bag of Words (CBOW) Model for the given (textual document \n",
    "3) using the below steps: \n",
    "a. Data preparation \n",
    "b. Generate training data \n",
    "c. Train model \n",
    "d. Output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfdc0456-dc50-4fa9-961e-17b5ee220906",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, Flatten\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2838d876-5399-4675-bb00-0fa0e747cb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPLACE THIS WITH YOUR TEXTUAL DOCUMENT 3\n",
    "text = \"\"\"\n",
    "    Artificial intelligence and machine learning are transforming industries. \n",
    "    Companies use data to train models that can understand language, \n",
    "    make predictions, and automate complex tasks.\n",
    "\"\"\"\n",
    "# PUT YOUR DOCUMENT 3 ABOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0ea5bb3-7447-4a3e-be9f-f3dbb332f78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 24\n",
      "Sequence: [2, 3, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 1, 21, 22, 23]\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "index_word = {v: k for k, v in word_index.items()}\n",
    "vocab_size = len(word_index) + 1\n",
    "\n",
    "sequence = tokenizer.texts_to_sequences([text])[0]\n",
    "\n",
    "print(\"Vocabulary Size:\", vocab_size)\n",
    "print(\"Sequence:\", sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d43e69b-a36e-4d26-aca2-66d2ce575244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Context samples:\n",
      " [[2 3 4 5]\n",
      " [3 1 5 6]\n",
      " [1 4 6 7]\n",
      " [4 5 7 8]\n",
      " [5 6 8 9]]\n",
      "\n",
      "Target samples:\n",
      " [1 4 5 6 7]\n"
     ]
    }
   ],
   "source": [
    "# b. Generate Training Data (CBOW)\n",
    "\n",
    "window_size = 2\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(window_size, len(sequence) - window_size):\n",
    "    context = [\n",
    "        sequence[i - 2],\n",
    "        sequence[i - 1],\n",
    "        sequence[i + 1],\n",
    "        sequence[i + 2]\n",
    "    ]\n",
    "    target = sequence[i]\n",
    "\n",
    "    X_train.append(context)\n",
    "    y_train.append(target)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "print(\"\\nContext samples:\\n\", X_train[:5])\n",
    "print(\"\\nTarget samples:\\n\", y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "732d5eb2-ae65-47db-b95a-f8823a62878f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                │              <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">792</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m)                │             \u001b[38;5;34m192\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m)                │              \u001b[38;5;34m72\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m792\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> (4.12 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,056\u001b[0m (4.12 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> (4.12 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,056\u001b[0m (4.12 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CBOW Model Training Complete!\n"
     ]
    }
   ],
   "source": [
    "# c. Train Model (CBOW)\n",
    "\n",
    "embedding_dim = 8\n",
    "\n",
    "input_layer = Input(shape=(4,))\n",
    "embedding_layer = Embedding(vocab_size, embedding_dim)(input_layer)\n",
    "\n",
    "hidden = Dense(embedding_dim, activation=\"linear\")(embedding_layer)\n",
    "hidden = Flatten()(hidden)\n",
    "\n",
    "output_layer = Dense(vocab_size, activation=\"softmax\")(hidden)\n",
    "\n",
    "cbow_model = Model(inputs=input_layer, outputs=output_layer)\n",
    "cbow_model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\")\n",
    "\n",
    "cbow_model.summary()\n",
    "\n",
    "cbow_model.fit(X_train, y_train, epochs=200, verbose=0)\n",
    "\n",
    "print(\"\\nCBOW Model Training Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60c2eb6e-a75f-4b23-9159-21e2bd784f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word Embeddings:\n",
      "and → [ 0.15621     0.32053098 -0.18528996  0.30319571  0.4884645   0.30342087\n",
      " -0.10042603  0.09858076]\n",
      "artificial → [-0.2318643   0.25763404  0.03483338  0.28602898  0.18428507  0.17300233\n",
      "  0.22551322  0.17132953]\n",
      "intelligence → [-0.29399934  0.05936664  0.2795036  -0.12943694 -0.36929822  0.1802812\n",
      "  0.02413907  0.2698054 ]\n",
      "machine → [-0.08952197 -0.22685188 -0.08893734 -0.27162734 -0.0663601  -0.35951588\n",
      " -0.3438871  -0.19163887]\n",
      "learning → [-0.1648227   0.4646425  -0.14915682 -0.17060828  0.1622629  -0.00453295\n",
      "  0.02649874  0.00562825]\n",
      "are → [ 0.28259823  0.36420196  0.389856    0.29321522  0.24533466 -0.13921128\n",
      "  0.29195583 -0.44840622]\n",
      "transforming → [-0.42768753  0.17902027 -0.4127369   0.27064502  0.17534049  0.2998569\n",
      " -0.3512172   0.35093302]\n",
      "industries → [ 0.28268582  0.38657907  0.19856858 -0.4175635   0.03208609 -0.3190877\n",
      "  0.18284974 -0.4132808 ]\n",
      "companies → [-0.1584337   0.34233493  0.24463023  0.17779505 -0.09825984  0.29114214\n",
      "  0.35129318  0.24656844]\n",
      "use → [-0.40062457 -0.39531514  0.03248615 -0.34703827 -0.37931114 -0.16627568\n",
      " -0.0585121  -0.07458898]\n",
      "data → [-0.06388909 -0.39650387 -0.11122277 -0.24633598 -0.37968567 -0.2508863\n",
      " -0.11884055  0.02507146]\n",
      "to → [ 0.30322596 -0.05645812  0.31895068  0.28157592 -0.20155862  0.21683156\n",
      "  0.4308906  -0.25459924]\n",
      "train → [ 0.13377817 -0.04912478  0.35926622  0.02972485 -0.12256226 -0.44204703\n",
      "  0.16954438 -0.22922678]\n",
      "models → [-0.355862   -0.1795374  -0.11012013  0.44678786  0.25820047  0.3666642\n",
      " -0.22333178  0.3177092 ]\n",
      "that → [-0.3904271   0.1962649   0.05362487 -0.06364859  0.2801485  -0.3361822\n",
      " -0.40897956  0.4014451 ]\n",
      "can → [-0.10291532 -0.50127834 -0.21587312 -0.32022366 -0.33518583 -0.30951807\n",
      " -0.34791914  0.02896598]\n",
      "understand → [ 0.44339865 -0.22629435  0.38184646 -0.10391334  0.07661565 -0.3487853\n",
      "  0.01375802 -0.27422556]\n",
      "language → [ 0.09506422  0.07330193 -0.14300066 -0.30605805  0.03888393 -0.37756565\n",
      "  0.1051217  -0.39123148]\n",
      "make → [ 0.16638193  0.13290338 -0.34132722  0.36429805  0.3251037   0.37113035\n",
      "  0.28008053 -0.08020428]\n",
      "predictions → [ 0.01043634 -0.35646296  0.05071857 -0.03353751 -0.4758269   0.17582002\n",
      "  0.37820378  0.13950102]\n",
      "automate → [ 0.03507401 -0.2713667  -0.23467243 -0.25361726 -0.27455914 -0.24843244\n",
      " -0.27720752 -0.09817581]\n",
      "complex → [ 0.26603922 -0.09710771 -0.27646866 -0.30795795  0.02243543 -0.28956392\n",
      " -0.06871191 -0.31120223]\n",
      "tasks → [ 0.06477388 -0.19065809  0.25011647  0.21016784 -0.30609006  0.27393833\n",
      "  0.16462713  0.2611628 ]\n"
     ]
    }
   ],
   "source": [
    "# d. Output – Word Embeddings\n",
    "\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "embedding_layer_obj = [layer for layer in cbow_model.layers if isinstance(layer, Embedding)][0]\n",
    "weights = embedding_layer_obj.get_weights()[0]\n",
    "\n",
    "print(\"\\nWord Embeddings:\")\n",
    "for word, idx in word_index.items():\n",
    "    print(f\"{word} → {weights[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f1a04af-f9b5-4edb-9f38-ec35bdf8cd54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking Word Similarity:\n",
      "Similarity(learning, intelligence): -0.0057946863\n",
      "Similarity(models, predictions): -0.09324876\n",
      "Similarity(data, companies): -0.5541615\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\n",
      "Context: ['machine', 'learning', 'are', 'transforming']\n",
      "Predicted Missing Word: to\n"
     ]
    }
   ],
   "source": [
    "# EXTRA SECTION: CHECK IF CBOW MODEL IS WORKING\n",
    "\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# Similarity function\n",
    "def similarity(w1, w2):\n",
    "    v1 = weights[word_index[w1]]\n",
    "    v2 = weights[word_index[w2]]\n",
    "    return dot(v1, v2) / (norm(v1) * norm(v2))\n",
    "\n",
    "print(\"\\nChecking Word Similarity:\")\n",
    "print(\"Similarity(learning, intelligence):\", similarity(\"learning\", \"intelligence\"))\n",
    "print(\"Similarity(models, predictions):\", similarity(\"models\", \"predictions\"))\n",
    "print(\"Similarity(data, companies):\", similarity(\"data\", \"companies\"))\n",
    "\n",
    "\n",
    "# Predict the missing target word from context\n",
    "context_words = [\"machine\", \"learning\", \"are\", \"transforming\"]\n",
    "\n",
    "context_ids = np.array([[word_index[w] for w in context_words]])\n",
    "\n",
    "pred = cbow_model.predict(context_ids)\n",
    "predicted_word = index_word[np.argmax(pred)]\n",
    "\n",
    "print(\"\\nContext:\", context_words)\n",
    "print(\"Predicted Missing Word:\", predicted_word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
